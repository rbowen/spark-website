<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview1 ScalaDoc  - org.apache.spark.streaming.dstream.PairDStreamFunctions</title><meta content="Spark 4.0.0 - preview1 ScalaDoc - org.apache.spark.streaming.dstream.PairDStreamFunctions" name="description"/><meta content="Spark 4.0.0 preview1 ScalaDoc org.apache.spark.streaming.dstream.PairDStreamFunctions" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../index.js"></script><script type="text/javascript" src="../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview1 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.streaming" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="streaming" class="anchorToMember"></a><a id="streaming:streaming" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title="Spark Streaming functionality."><span class="name">streaming</span></a></span><p class="shortcomment cmt">Spark Streaming functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Spark Streaming functionality. <a href="../StreamingContext.html" name="org.apache.spark.streaming.StreamingContext" id="org.apache.spark.streaming.StreamingContext" class="extype">org.apache.spark.streaming.StreamingContext</a> serves as the main
entry point to Spark Streaming, while <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">org.apache.spark.streaming.dstream.DStream</a> is the data
type representing a continuous sequence of RDDs, representing a continuous stream of data.</p><p>In addition, <a href="" name="org.apache.spark.streaming.dstream.PairDStreamFunctions" id="org.apache.spark.streaming.dstream.PairDStreamFunctions" class="extype">org.apache.spark.streaming.dstream.PairDStreamFunctions</a> contains operations
available only on DStreams
of key-value pairs, such as <code>groupByKey</code> and <code>reduceByKey</code>. These operations are automatically
available on any DStream of the right type (e.g. DStream[(Int, Int)] through implicit
conversions.</p><p>For the Java API of Spark Streaming, take a look at the
<a href="../api/java/JavaStreamingContext.html" name="org.apache.spark.streaming.api.java.JavaStreamingContext" id="org.apache.spark.streaming.api.java.JavaStreamingContext" class="extype">org.apache.spark.streaming.api.java.JavaStreamingContext</a> which serves as the entry point, and
the <a href="../api/java/JavaDStream.html" name="org.apache.spark.streaming.api.java.JavaDStream" id="org.apache.spark.streaming.api.java.JavaDStream" class="extype">org.apache.spark.streaming.api.java.JavaDStream</a> and the
<a href="../api/java/JavaPairDStream.html" name="org.apache.spark.streaming.api.java.JavaPairDStream" id="org.apache.spark.streaming.api.java.JavaPairDStream" class="extype">org.apache.spark.streaming.api.java.JavaPairDStream</a> which have the DStream functionality.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.streaming.dstream" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="dstream" class="anchorToMember"></a><a id="dstream:dstream" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index.html" title="Various implementations of DStream's."><span class="name">dstream</span></a></span><p class="shortcomment cmt">Various implementations of DStream's.</p><div class="fullcomment"><div class="comment cmt"><p>Various implementations of DStream's.</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.streaming" id="org.apache.spark.streaming" class="extype">streaming</a></dd><dt>See also</dt><dd><span class="cmt"><p><a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">org.apache.spark.streaming.dstream.DStream</a></p></span></dd></dl></div></li><li class="current-entities indented5"><span class="separator"></span> <a href="ConstantInputDStream.html" title="An input stream that always returns the same RDD on each time step." class="class"></a><a href="ConstantInputDStream.html" title="An input stream that always returns the same RDD on each time step.">ConstantInputDStream</a></li><li class="current-entities indented5"><a href="DStream$.html" title="" class="object"></a> <a href="DStream.html" title="A Discretized Stream (DStream), the basic abstraction in Spark Streaming, is a continuous sequence of RDDs (of the same type) representing a continuous stream of data (see org.apache.spark.rdd.RDD in the Spark core documentation for more details on RDDs)." class="class"></a><a href="DStream.html" title="A Discretized Stream (DStream), the basic abstraction in Spark Streaming, is a continuous sequence of RDDs (of the same type) representing a continuous stream of data (see org.apache.spark.rdd.RDD in the Spark core documentation for more details on RDDs).">DStream</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="InputDStream.html" title="This is the abstract base class for all input streams." class="class"></a><a href="InputDStream.html" title="This is the abstract base class for all input streams.">InputDStream</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="MapWithStateDStream.html" title="DStream representing the stream of data generated by mapWithState operation on a pair DStream." class="class"></a><a href="MapWithStateDStream.html" title="DStream representing the stream of data generated by mapWithState operation on a pair DStream.">MapWithStateDStream</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="" title="Extra functions available on DStream of (key, value) pairs through an implicit conversion." class="class"></a><a href="" title="Extra functions available on DStream of (key, value) pairs through an implicit conversion.">PairDStreamFunctions</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="ReceiverInputDStream.html" title="Abstract class for defining any org.apache.spark.streaming.dstream.InputDStream that has to start a receiver on worker nodes to receive external data." class="class"></a><a href="ReceiverInputDStream.html" title="Abstract class for defining any org.apache.spark.streaming.dstream.InputDStream that has to start a receiver on worker nodes to receive external data.">ReceiverInputDStream</a></li></ul></div></div><div id="content"><body class="class type"><div id="definition"><div class="big-circle class">c</div><p id="owner"><a href="../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../index.html" name="org.apache.spark.streaming" id="org.apache.spark.streaming" class="extype">streaming</a>.<a href="index.html" name="org.apache.spark.streaming.dstream" id="org.apache.spark.streaming.dstream" class="extype">dstream</a></p><h1>PairDStreamFunctions<span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html" title="Permalink"><i class="material-icons"></i></a></span></h1><h3><span class="morelinks"></span></h3></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier"></span> <span class="kind">class</span></span> <span class="symbol"><span class="name">PairDStreamFunctions</span><span class="tparams">[<span name="K">K</span>, <span name="V">V</span>]</span><span class="result"> extends <span name="scala.Serializable" class="extype">Serializable</span></span></span></h4><div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Extra functions available on DStream of (key, value) pairs through an implicit conversion.
</p></div><dl class="attributes block"><dt>Source</dt><dd><a href="https://github.com/apache/spark/tree/v4.0.0-preview1/streaming/src/main/scala/org/apache/spark/streaming/dstream/PairDStreamFunctions.scala" target="_blank">PairDStreamFunctions.scala</a></dd></dl><div class="toggleContainer"><div class="toggle block"><span>Linear Supertypes</span><div class="superTypes hiddenContent"><a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a>, <span name="scala.AnyRef" class="extype">AnyRef</span>, <span name="scala.Any" class="extype">Any</span></div></div></div></div><div id="mbrsel"><div class="toggle"></div><div id="memberfilter"><i class="material-icons arrow"></i><span class="input"><input placeholder="Filter all members" id="mbrsel-input" type="text" accesskey="/"/></span><i class="clear material-icons"></i></div><div id="filterby"><div id="order"><span class="filtertype">Ordering</span><ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By Inheritance</span></li></ol></div><div class="ancestors"><span class="filtertype">Inherited<br/></span><ol id="linearization"><li class="in" name="org.apache.spark.streaming.dstream.PairDStreamFunctions"><span>PairDStreamFunctions</span></li><li class="in" name="java.io.Serializable"><span>Serializable</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li></ol></div><div class="ancestors"><span class="filtertype"></span><ol><li class="hideall out"><span>Hide All</span></li><li class="showall in"><span>Show All</span></li></ol></div><div id="visbl"><span class="filtertype">Visibility</span><ol><li class="public in"><span>Public</span></li><li class="protected out"><span>Protected</span></li></ol></div></div></div><div id="template"><div id="allMembers"><div id="constructors" class="members"><h3>Instance Constructors</h3><ol><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#&lt;init&gt;" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="&lt;init&gt;(self:org.apache.spark.streaming.dstream.DStream[(K,V)])(implicitkt:scala.reflect.ClassTag[K],implicitvt:scala.reflect.ClassTag[V],implicitord:Ordering[K]):org.apache.spark.streaming.dstream.PairDStreamFunctions[K,V]" class="anchorToMember"></a><a id="&lt;init&gt;:PairDStreamFunctions[K,V]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#&lt;init&gt;(self:org.apache.spark.streaming.dstream.DStream[(K,V)])(implicitkt:scala.reflect.ClassTag[K],implicitvt:scala.reflect.ClassTag[V],implicitord:Ordering[K]):org.apache.spark.streaming.dstream.PairDStreamFunctions[K,V]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">new</span></span> <span class="symbol"><span class="name">PairDStreamFunctions</span><span class="params">(<span name="self">self: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="kt">kt: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>]</span>, <span name="vt">vt: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>]</span>, <span name="ord">ord: <span name="scala.Ordering" class="extype">Ordering</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>]</span>)</span></span></li></ol></div><div class="values members"><h3>Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#!=" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="!=(x$1:Any):Boolean" class="anchorToMember"></a><a id="!=(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#!=(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef###" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="##:Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html###:Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $hash$hash">##</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#==" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="==(x$1:Any):Boolean" class="anchorToMember"></a><a id="==(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#==(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.Any#asInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="asInstanceOf[T0]:T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#asInstanceOf[T0]:T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Any.asInstanceOf.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#clone" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="clone():Object" class="anchorToMember"></a><a id="clone():AnyRef" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#clone():Object" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">clone</span><span class="params">()</span><span class="result">: <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.CloneNotSupportedException]</span></span>)</span> <span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#cogroup" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$15:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]" class="anchorToMember"></a><a id="cogroup[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(Iterable[V],Iterable[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$15:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
The supplied org.apache.spark.Partitioner is used to partition the generated RDDs.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#cogroup" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$14:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]" class="anchorToMember"></a><a id="cogroup[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(Iterable[V],Iterable[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$14:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#cogroup" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$13:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]" class="anchorToMember"></a><a id="cogroup[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(Iterable[V],Iterable[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#cogroup[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$13:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Iterable[V],Iterable[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">cogroup</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.cogroup.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'cogroup' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with Spark's default number
of partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#combineByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="combineByKey[C](createCombiner:V=&gt;C,mergeValue:(C,V)=&gt;C,mergeCombiner:(C,C)=&gt;C,partitioner:org.apache.spark.Partitioner,mapSideCombine:Boolean)(implicitevidence$1:scala.reflect.ClassTag[C]):org.apache.spark.streaming.dstream.DStream[(K,C)]" class="anchorToMember"></a><a id="combineByKey[C]((V)=&gt;C,(C,V)=&gt;C,(C,C)=&gt;C,Partitioner,Boolean)(ClassTag[C]):DStream[(K,C)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#combineByKey[C](createCombiner:V=&gt;C,mergeValue:(C,V)=&gt;C,mergeCombiner:(C,C)=&gt;C,partitioner:org.apache.spark.Partitioner,mapSideCombine:Boolean)(implicitevidence$1:scala.reflect.ClassTag[C]):org.apache.spark.streaming.dstream.DStream[(K,C)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">combineByKey</span><span class="tparams">[<span name="C">C</span>]</span><span class="params">(<span name="createCombiner">createCombiner: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span></span>, <span name="mergeValue">mergeValue: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span></span>, <span name="mergeCombiner">mergeCombiner: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>, <span name="mapSideCombine">mapSideCombine: <span name="scala.Boolean" class="extype">Boolean</span> = <span class="symbol">true</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.combineByKey.C" class="extype">C</span>)]</span></span><p class="shortcomment cmt">Combine elements of each key in DStream's RDDs using custom functions.</p><div class="fullcomment"><div class="comment cmt"><p>Combine elements of each key in DStream's RDDs using custom functions. This is similar to the
combineByKey for RDDs. Please refer to combineByKey in
org.apache.spark.rdd.PairRDDFunctions in the Spark core documentation for more information.
</p></div></div></li><li class="indented0 " name="scala.AnyRef#eq" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="eq(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="eq(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#eq(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#equals" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="equals(x$1:Object):Boolean" class="anchorToMember"></a><a id="equals(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#equals(x$1:Object):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#flatMapValues" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="flatMapValues[U](flatMapValuesFunc:V=&gt;IterableOnce[U])(implicitevidence$12:scala.reflect.ClassTag[U]):org.apache.spark.streaming.dstream.DStream[(K,U)]" class="anchorToMember"></a><a id="flatMapValues[U]((V)=&gt;IterableOnce[U])(ClassTag[U]):DStream[(K,U)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#flatMapValues[U](flatMapValuesFunc:V=&gt;IterableOnce[U])(implicitevidence$12:scala.reflect.ClassTag[U]):org.apache.spark.streaming.dstream.DStream[(K,U)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">flatMapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="flatMapValuesFunc">flatMapValuesFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="scala.IterableOnce" class="extype">IterableOnce</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.flatMapValues.U" class="extype">U</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.flatMapValues.U" class="extype">U</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.flatMapValues.U" class="extype">U</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying a flatmap function to the value of each key-value pairs in
'this' DStream without changing the key.</p></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#fullOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$27:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]" class="anchorToMember"></a><a id="fullOuterJoin[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(Option[V],Option[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$27:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">fullOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#fullOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$26:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]" class="anchorToMember"></a><a id="fullOuterJoin[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(Option[V],Option[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$26:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">fullOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#fullOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$25:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]" class="anchorToMember"></a><a id="fullOuterJoin[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(Option[V],Option[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#fullOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$25:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],Option[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">fullOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.fullOuterJoin.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'full outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div></li><li class="indented0 " name="scala.AnyRef#getClass" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="getClass():Class[_]" class="anchorToMember"></a><a id="getClass():Class[_&lt;:AnyRef]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#getClass():Class[_]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">getClass</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html#java.lang.Class" name="java.lang.Class" id="java.lang.Class" class="extype">Class</a>[_ &lt;: <span name="scala.AnyRef" class="extype">AnyRef</span>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKey(partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKey(Partitioner):DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKey</span><span class="params">(<span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> on each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> on each RDD. The supplied
org.apache.spark.Partitioner is used to control the partitioning of each RDD.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKey(numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKey(Int):DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey(numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKey</span><span class="params">(<span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKey():org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKey():DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKey():org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKey</span><span class="params">()</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> to each RDD. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKeyAndWindow(Duration,Duration,Partitioner):DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Create a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD in the new
                      DStream.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKeyAndWindow(Duration,Duration,Int):DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.groupByKey()</code>, but applies it over a sliding window.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream; if not specified
                      then Spark's default number of partitions will be used</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKeyAndWindow(Duration,Duration):DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. Similar to
<code>DStream.groupByKey()</code>, but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#groupByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" class="anchorToMember"></a><a id="groupByKeyAndWindow(Duration):DStream[(K,Iterable[V])]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#groupByKeyAndWindow(windowDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,Iterable[V])]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">groupByKeyAndWindow</span><span class="params">(<span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Iterable" class="extype">Iterable</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>])]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>groupByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>groupByKey</code> over a sliding window. This is similar to
<code>DStream.groupByKey()</code> but applies it over a sliding window. The new DStream generates RDDs
with the same interval as this DStream. Hash partitioning is used to generate the RDDs with
Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#hashCode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="hashCode():Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#hashCode():Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.Any#isInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="isInstanceOf[T0]:Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#isInstanceOf[T0]:Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#join" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$18:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]" class="anchorToMember"></a><a id="join[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(V,W))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$18:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
The supplied org.apache.spark.Partitioner is used to control the partitioning of each RDD.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#join" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$17:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]" class="anchorToMember"></a><a id="join[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(V,W))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$17:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#join" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$16:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]" class="anchorToMember"></a><a id="join[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(V,W))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#join[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$16:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,W))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">join</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.join.W" class="extype">W</span>))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'join' between RDDs of <code>this</code> DStream and <code>other</code> DStream.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#leftOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$21:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]" class="anchorToMember"></a><a id="leftOuterJoin[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(V,Option[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$21:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#leftOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$20:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]" class="anchorToMember"></a><a id="leftOuterJoin[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(V,Option[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$20:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#leftOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$19:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]" class="anchorToMember"></a><a id="leftOuterJoin[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(V,Option[W]))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#leftOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$19:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(V,Option[W]))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">leftOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.leftOuterJoin.W" class="extype">W</span>]))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'left outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#mapValues" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="mapValues[U](mapValuesFunc:V=&gt;U)(implicitevidence$11:scala.reflect.ClassTag[U]):org.apache.spark.streaming.dstream.DStream[(K,U)]" class="anchorToMember"></a><a id="mapValues[U]((V)=&gt;U)(ClassTag[U]):DStream[(K,U)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapValues[U](mapValuesFunc:V=&gt;U)(implicitevidence$11:scala.reflect.ClassTag[U]):org.apache.spark.streaming.dstream.DStream[(K,U)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">mapValues</span><span class="tparams">[<span name="U">U</span>]</span><span class="params">(<span name="mapValuesFunc">mapValuesFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapValues.U" class="extype">U</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapValues.U" class="extype">U</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapValues.U" class="extype">U</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying a map function to the value of each key-value pairs in
'this' DStream without changing the key.</p></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#mapWithState" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="mapWithState[StateType,MappedType](spec:org.apache.spark.streaming.StateSpec[K,V,StateType,MappedType])(implicitevidence$2:scala.reflect.ClassTag[StateType],implicitevidence$3:scala.reflect.ClassTag[MappedType]):org.apache.spark.streaming.dstream.MapWithStateDStream[K,V,StateType,MappedType]" class="anchorToMember"></a><a id="mapWithState[StateType,MappedType](StateSpec[K,V,StateType,MappedType])(ClassTag[StateType],ClassTag[MappedType]):MapWithStateDStream[K,V,StateType,MappedType]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#mapWithState[StateType,MappedType](spec:org.apache.spark.streaming.StateSpec[K,V,StateType,MappedType])(implicitevidence$2:scala.reflect.ClassTag[StateType],implicitevidence$3:scala.reflect.ClassTag[MappedType]):org.apache.spark.streaming.dstream.MapWithStateDStream[K,V,StateType,MappedType]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">mapWithState</span><span class="tparams">[<span name="StateType">StateType</span>, <span name="MappedType">MappedType</span>]</span><span class="params">(<span name="spec">spec: <a href="../StateSpec.html" name="org.apache.spark.streaming.StateSpec" id="org.apache.spark.streaming.StateSpec" class="extype">StateSpec</a>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapWithState.StateType" class="extype">StateType</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapWithState.MappedType" class="extype">MappedType</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapWithState.StateType" class="extype">StateType</span>]</span>, <span name="arg1">arg1: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapWithState.MappedType" class="extype">MappedType</span>]</span>)</span><span class="result">: <a href="MapWithStateDStream.html" name="org.apache.spark.streaming.dstream.MapWithStateDStream" id="org.apache.spark.streaming.dstream.MapWithStateDStream" class="extype">MapWithStateDStream</a>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapWithState.StateType" class="extype">StateType</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.mapWithState.MappedType" class="extype">MappedType</span>]</span></span><p class="shortcomment cmt">Return a <a href="MapWithStateDStream.html" name="org.apache.spark.streaming.dstream.MapWithStateDStream" id="org.apache.spark.streaming.dstream.MapWithStateDStream" class="extype">MapWithStateDStream</a> by applying a function to every key-value element of
<code>this</code> stream, while maintaining some state data for each unique key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a <a href="MapWithStateDStream.html" name="org.apache.spark.streaming.dstream.MapWithStateDStream" id="org.apache.spark.streaming.dstream.MapWithStateDStream" class="extype">MapWithStateDStream</a> by applying a function to every key-value element of
<code>this</code> stream, while maintaining some state data for each unique key. The mapping function
and other specification (e.g. partitioners, timeouts, initial state data, etc.) of this
transformation can be specified using <code>StateSpec</code> class. The state data is accessible in
as a parameter of type <code>State</code> in the mapping function.</p><p>Example of using <code>mapWithState</code>:</p><pre><span class="cmt">// A mapping function that maintains an integer state and return a String</span>
<span class="kw">def</span> mappingFunction(key: <span class="std">String</span>, value: <span class="std">Option</span>[<span class="std">Int</span>], state: State[<span class="std">Int</span>]): <span class="std">Option</span>[<span class="std">String</span>] = {
  <span class="cmt">// Use state.exists(), state.get(), state.update() and state.remove()</span>
  <span class="cmt">// to manage state, and return the necessary string</span>
}

<span class="kw">val</span> spec = StateSpec.function(mappingFunction).numPartitions(<span class="num">10</span>)

<span class="kw">val</span> mapWithStateDStream = keyValueDStream.mapWithState[StateType, MappedType](spec)</pre></div><dl class="paramcmts block"><dt class="tparam">StateType</dt><dd class="cmt"><p>Class type of the state data</p></dd><dt class="tparam">MappedType</dt><dd class="cmt"><p>Class type of the mapped data</p></dd><dt class="param">spec</dt><dd class="cmt"><p>Specification of this transformation</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#ne" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ne(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="ne(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#ne(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notify" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notify():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#notify():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notifyAll" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notifyAll():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#notifyAll():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKey(reduceFunc:(V,V)=&gt;V,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKey((V,V)=&gt;V,Partitioner):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(reduceFunc:(V,V)=&gt;V,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKey(reduceFunc:(V,V)=&gt;V,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKey((V,V)=&gt;V,Int):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(reduceFunc:(V,V)=&gt;V,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the supplied reduce function. Hash partitioning is used to generate the RDDs
with <code>numPartitions</code> partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKey(reduceFunc:(V,V)=&gt;V):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKey((V,V)=&gt;V):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKey(reduceFunc:(V,V)=&gt;V):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKey</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> to each RDD.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> to each RDD. The values for each key are
merged using the associative and commutative reduce function. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,invReduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner,filterFunc:((K,V))=&gt;Boolean):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKeyAndWindow((V,V)=&gt;V,(V,V)=&gt;V,Duration,Duration,Partitioner,((K,V))=&gt;Boolean):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,invReduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner,filterFunc:((K,V))=&gt;Boolean):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="invReduceFunc">invReduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>, <span name="filterFunc">filterFunc: ((<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)) =&gt; <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)
 2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)
This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
However, it is applicable to only "invertible reduce functions".</li></ol></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative and commutative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD in the new
                      DStream.</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>Optional function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,invReduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int,filterFunc:((K,V))=&gt;Boolean):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKeyAndWindow((V,V)=&gt;V,(V,V)=&gt;V,Duration,Duration,Int,((K,V))=&gt;Boolean):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,invReduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int,filterFunc:((K,V))=&gt;Boolean):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="invReduceFunc">invReduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a> = <span class="symbol"><span class="name"><a href="DStream.html#slideDuration:org.apache.spark.streaming.Duration">self.slideDuration</a></span></span></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span> = <span class="symbol"><span class="name"><a href="../../SparkContext.html#defaultParallelism:Int">ssc.sc.defaultParallelism</a></span></span></span>, <span name="filterFunc">filterFunc: ((<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)) =&gt; <span name="scala.Boolean" class="extype">Boolean</span> = <span class="symbol">null</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying incremental <code>reduceByKey</code> over a sliding window.
The reduced value of over a new window is calculated using the old window's reduced value :</p><ol class="decimal"><li>reduce the new values that entered the window (e.g., adding new counts)</li></ol><p> 2. "inverse reduce" the old values that left the window (e.g., subtracting old counts)</p><p>This is more efficient than reduceByKeyAndWindow without "inverse reduce" function.
However, it is applicable to only "invertible reduce functions".
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative and commutative reduce function</p></dd><dt class="param">invReduceFunc</dt><dd class="cmt"><p>inverse reduce function; such that for all y, invertible x:
                     <code>invReduceFunc(reduceFunc(x, y), x) = y</code></p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">filterFunc</dt><dd class="cmt"><p>Optional function to filter expired key-value pairs;
                      only pairs that satisfy the function are retained</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKeyAndWindow((V,V)=&gt;V,Duration,Duration,Partitioner):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,partitioner:org.apache.spark.Partitioner):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. Similar to
<code>DStream.reduceByKey()</code>, but applies it over a sliding window.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative and commutative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>partitioner for controlling the partitioning of each RDD
                      in the new DStream.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKeyAndWindow((V,V)=&gt;V,Duration,Duration,Int):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration,numPartitions:Int):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative and commutative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>number of partitions of each RDD in the new DStream.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKeyAndWindow((V,V)=&gt;V,Duration,Duration):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration,slideDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>, <span name="slideDuration">slideDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window. This is similar to
<code>DStream.reduceByKey()</code> but applies it over a sliding window. Hash partitioning is used to
generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative and commutative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd><dt class="param">slideDuration</dt><dd class="cmt"><p>sliding interval of the window (i.e., the interval after which
                      the new DStream will generate RDDs); must be a multiple of this
                      DStream's batching interval</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#reduceByKeyAndWindow" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,V)]" class="anchorToMember"></a><a id="reduceByKeyAndWindow((V,V)=&gt;V,Duration):DStream[(K,V)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#reduceByKeyAndWindow(reduceFunc:(V,V)=&gt;V,windowDuration:org.apache.spark.streaming.Duration):org.apache.spark.streaming.dstream.DStream[(K,V)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">reduceByKeyAndWindow</span><span class="params">(<span name="reduceFunc">reduceFunc: (<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>) =&gt; <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span></span>, <span name="windowDuration">windowDuration: <a href="../Duration.html" name="org.apache.spark.streaming.Duration" id="org.apache.spark.streaming.Duration" class="extype">Duration</a></span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>)]</span></span><p class="shortcomment cmt">Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying <code>reduceByKey</code> over a sliding window on <code>this</code> DStream.
Similar to <code>DStream.reduceByKey()</code>, but applies it over a sliding window. The new DStream
generates RDDs with the same interval as this DStream. Hash partitioning is used to generate
the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="param">reduceFunc</dt><dd class="cmt"><p>associative and commutative reduce function</p></dd><dt class="param">windowDuration</dt><dd class="cmt"><p>width of the window; must be a multiple of this DStream's
                      batching interval</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#rightOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$24:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]" class="anchorToMember"></a><a id="rightOuterJoin[W](DStream[(K,W)],Partitioner)(ClassTag[W]):DStream[(K,(Option[V],W))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],partitioner:org.apache.spark.Partitioner)(implicitevidence$24:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. The supplied org.apache.spark.Partitioner is used to control
the partitioning of each RDD.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#rightOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$23:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]" class="anchorToMember"></a><a id="rightOuterJoin[W](DStream[(K,W)],Int)(ClassTag[W]):DStream[(K,(Option[V],W))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)],numPartitions:Int)(implicitevidence$23:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>)]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with <code>numPartitions</code>
partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#rightOuterJoin" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$22:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]" class="anchorToMember"></a><a id="rightOuterJoin[W](DStream[(K,W)])(ClassTag[W]):DStream[(K,(Option[V],W))]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#rightOuterJoin[W](other:org.apache.spark.streaming.dstream.DStream[(K,W)])(implicitevidence$22:scala.reflect.ClassTag[W]):org.apache.spark.streaming.dstream.DStream[(K,(Option[V],W))]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">rightOuterJoin</span><span class="tparams">[<span name="W">W</span>]</span><span class="params">(<span name="other">other: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, (<span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.rightOuterJoin.W" class="extype">W</span>))]</span></span><p class="shortcomment cmt">Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new DStream by applying 'right outer join' between RDDs of <code>this</code> DStream and
<code>other</code> DStream. Hash partitioning is used to generate the RDDs with Spark's default
number of partitions.
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsHadoopFiles" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="saveAsHadoopFiles(prefix:String,suffix:String,keyClass:Class[_],valueClass:Class[_],outputFormatClass:Class[_&lt;:org.apache.hadoop.mapred.OutputFormat[_,_]],conf:org.apache.hadoop.mapred.JobConf):Unit" class="anchorToMember"></a><a id="saveAsHadoopFiles(String,String,Class[_],Class[_],Class[_&lt;:OutputFormat[_,_]],JobConf):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles(prefix:String,suffix:String,keyClass:Class[_],valueClass:Class[_],outputFormatClass:Class[_&lt;:org.apache.hadoop.mapred.OutputFormat[_,_]],conf:org.apache.hadoop.mapred.JobConf):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">saveAsHadoopFiles</span><span class="params">(<span name="prefix">prefix: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="suffix">suffix: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="keyClass">keyClass: <span name="scala.Predef.Class" class="extype">Class</span>[_]</span>, <span name="valueClass">valueClass: <span name="scala.Predef.Class" class="extype">Class</span>[_]</span>, <span name="outputFormatClass">outputFormatClass: <span name="scala.Predef.Class" class="extype">Class</span>[_ &lt;: <span name="org.apache.hadoop.mapred.OutputFormat" class="extype">OutputFormat</span>[_, _]]</span>, <span name="conf">conf: <span name="org.apache.hadoop.mapred.JobConf" class="extype">JobConf</span> = <span class="defval"><span class="name"><a href="../StreamingContext.html#sparkContext:org.apache.spark.SparkContext">new JobConf(ssc.sparkContext.hadoopConfiguration)</a></span></span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsHadoopFiles" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="saveAsHadoopFiles[F&lt;:org.apache.hadoop.mapred.OutputFormat[K,V]](prefix:String,suffix:String)(implicitfm:scala.reflect.ClassTag[F]):Unit" class="anchorToMember"></a><a id="saveAsHadoopFiles[F&lt;:OutputFormat[K,V]](String,String)(ClassTag[F]):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsHadoopFiles[F&lt;:org.apache.hadoop.mapred.OutputFormat[K,V]](prefix:String,suffix:String)(implicitfm:scala.reflect.ClassTag[F]):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">saveAsHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span name="org.apache.hadoop.mapred.OutputFormat" class="extype">OutputFormat</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>]</span>]</span><span class="params">(<span name="prefix">prefix: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="suffix">suffix: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="fm">fm: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.saveAsHadoopFiles.F" class="extype">F</span>]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval
is generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix"
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsNewAPIHadoopFiles" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="saveAsNewAPIHadoopFiles(prefix:String,suffix:String,keyClass:Class[_],valueClass:Class[_],outputFormatClass:Class[_&lt;:org.apache.hadoop.mapreduce.OutputFormat[_,_]],conf:org.apache.hadoop.conf.Configuration):Unit" class="anchorToMember"></a><a id="saveAsNewAPIHadoopFiles(String,String,Class[_],Class[_],Class[_&lt;:OutputFormat[_,_]],Configuration):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles(prefix:String,suffix:String,keyClass:Class[_],valueClass:Class[_],outputFormatClass:Class[_&lt;:org.apache.hadoop.mapreduce.OutputFormat[_,_]],conf:org.apache.hadoop.conf.Configuration):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">saveAsNewAPIHadoopFiles</span><span class="params">(<span name="prefix">prefix: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="suffix">suffix: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="keyClass">keyClass: <span name="scala.Predef.Class" class="extype">Class</span>[_]</span>, <span name="valueClass">valueClass: <span name="scala.Predef.Class" class="extype">Class</span>[_]</span>, <span name="outputFormatClass">outputFormatClass: <span name="scala.Predef.Class" class="extype">Class</span>[_ &lt;: <span name="org.apache.hadoop.mapreduce.OutputFormat" class="extype">OutputFormat</span>[_, _]]</span>, <span name="conf">conf: <span name="org.apache.hadoop.conf.Configuration" class="extype">Configuration</span> = <span class="defval"><span class="name"><a href="../StreamingContext.html#sparkContext:org.apache.spark.SparkContext">ssc.sparkContext.hadoopConfiguration</a></span></span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".
</p></div></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#saveAsNewAPIHadoopFiles" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="saveAsNewAPIHadoopFiles[F&lt;:org.apache.hadoop.mapreduce.OutputFormat[K,V]](prefix:String,suffix:String)(implicitfm:scala.reflect.ClassTag[F]):Unit" class="anchorToMember"></a><a id="saveAsNewAPIHadoopFiles[F&lt;:OutputFormat[K,V]](String,String)(ClassTag[F]):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#saveAsNewAPIHadoopFiles[F&lt;:org.apache.hadoop.mapreduce.OutputFormat[K,V]](prefix:String,suffix:String)(implicitfm:scala.reflect.ClassTag[F]):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">saveAsNewAPIHadoopFiles</span><span class="tparams">[<span name="F">F &lt;: <span name="org.apache.hadoop.mapreduce.OutputFormat" class="extype">OutputFormat</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>]</span>]</span><span class="params">(<span name="prefix">prefix: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="suffix">suffix: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="fm">fm: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.saveAsNewAPIHadoopFiles.F" class="extype">F</span>]</span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><p class="shortcomment cmt">Save each RDD in <code>this</code> DStream as a Hadoop file.</p><div class="fullcomment"><div class="comment cmt"><p>Save each RDD in <code>this</code> DStream as a Hadoop file. The file name at each batch interval is
generated based on <code>prefix</code> and <code>suffix</code>: "prefix-TIME_IN_MS.suffix".
</p></div></div></li><li class="indented0 " name="scala.AnyRef#synchronized" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="synchronized[T0](x$1:=&gt;T0):T0" class="anchorToMember"></a><a id="synchronized[T0](=&gt;T0):T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#synchronized[T0](x$1:=&gt;T0):T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: =&gt; <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span>)</span><span class="result">: <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#toString" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="toString():String" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#toString():String" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">toString</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html#java.lang.String" name="java.lang.String" id="java.lang.String" class="extype">String</a></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:(org.apache.spark.streaming.Time,K,Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean,initialRDD:Option[org.apache.spark.rdd.RDD[(K,S)]])(implicitevidence$10:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Time,K,Seq[V],Option[S])=&gt;Option[S],Partitioner,Boolean,Option[RDD[(K,S)]])(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:(org.apache.spark.streaming.Time,K,Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean,initialRDD:Option[org.apache.spark.rdd.RDD[(K,S)]])(implicitevidence$10:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<a href="../Time.html" name="org.apache.spark.streaming.Time" id="org.apache.spark.streaming.Time" class="extype">Time</a>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]) =&gt; <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>, <span name="rememberPartitioner">rememberPartitioner: <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="initialRDD">initialRDD: <span name="scala.Option" class="extype">Option</span>[<a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">RDD</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]] = <span class="symbol">None</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
In every batch the updateFunc will be called for each state even if there are no new values.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:Iterator[(K,Seq[V],Option[S])]=&gt;Iterator[(K,S)],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean,initialRDD:org.apache.spark.rdd.RDD[(K,S)])(implicitevidence$9:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Iterator[(K,Seq[V],Option[S])])=&gt;Iterator[(K,S)],Partitioner,Boolean,RDD[(K,S)])(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:Iterator[(K,Seq[V],Option[S])]=&gt;Iterator[(K,S)],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean,initialRDD:org.apache.spark.rdd.RDD[(K,S)])(implicitevidence$9:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span name="scala.Iterator" class="extype">Iterator</span>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>])]) =&gt; <span name="scala.Iterator" class="extype">Iterator</span>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>, <span name="rememberPartitioner">rememberPartitioner: <span name="scala.Boolean" class="extype">Boolean</span></span>, <span name="initialRDD">initialRDD: <a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">RDD</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
In every batch the updateFunc will be called for each state even if there are no new values.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. Note, that this function may generate a different
                  tuple with a different key than the input key. Therefore keys may be removed
                  or added in this way. It is up to the developer to decide whether to
                  remember the  partitioner despite the key being changed.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream</p></dd><dt class="param">rememberPartitioner</dt><dd class="cmt"><p>Whether to remember the partitioner object in the generated RDDs.</p></dd><dt class="param">initialRDD</dt><dd class="cmt"><p>initial state value of each key.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner,initialRDD:org.apache.spark.rdd.RDD[(K,S)])(implicitevidence$8:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Seq[V],Option[S])=&gt;Option[S],Partitioner,RDD[(K,S)])(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner,initialRDD:org.apache.spark.rdd.RDD[(K,S)])(implicitevidence$8:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]) =&gt; <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>, <span name="initialRDD">initialRDD: <a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">RDD</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
In every batch the updateFunc will be called for each state even if there are no new values.
org.apache.spark.Partitioner is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream.</p></dd><dt class="param">initialRDD</dt><dd class="cmt"><p>initial state value of each key.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:Iterator[(K,Seq[V],Option[S])]=&gt;Iterator[(K,S)],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean)(implicitevidence$7:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Iterator[(K,Seq[V],Option[S])])=&gt;Iterator[(K,S)],Partitioner,Boolean)(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:Iterator[(K,Seq[V],Option[S])]=&gt;Iterator[(K,S)],partitioner:org.apache.spark.Partitioner,rememberPartitioner:Boolean)(implicitevidence$7:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span name="scala.Iterator" class="extype">Iterator</span>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>])]) =&gt; <span name="scala.Iterator" class="extype">Iterator</span>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>, <span name="rememberPartitioner">rememberPartitioner: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
In every batch the updateFunc will be called for each state even if there are no new values.
<a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">org.apache.spark.Partitioner</a> is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. Note, that this function may generate a different
                  tuple with a different key than the input key. Therefore keys may be removed
                  or added in this way. It is up to the developer to decide whether to
                  remember the partitioner despite the key being changed.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream</p></dd><dt class="param">rememberPartitioner</dt><dd class="cmt"><p>Whether to remember the partitioner object in the generated RDDs.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner)(implicitevidence$6:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Seq[V],Option[S])=&gt;Option[S],Partitioner)(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],partitioner:org.apache.spark.Partitioner)(implicitevidence$6:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]) =&gt; <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>, <span name="partitioner">partitioner: <a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">Partitioner</a></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of the key.
In every batch the updateFunc will be called for each state even if there are no new values.
<a href="../../Partitioner.html" name="org.apache.spark.Partitioner" id="org.apache.spark.Partitioner" class="extype">org.apache.spark.Partitioner</a> is used to control the partitioning of each RDD.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">partitioner</dt><dd class="cmt"><p>Partitioner for controlling the partitioning of each RDD in the new
                   DStream.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],numPartitions:Int)(implicitevidence$5:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Seq[V],Option[S])=&gt;Option[S],Int)(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S],numPartitions:Int)(implicitevidence$5:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]) =&gt; <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
In every batch the updateFunc will be called for each state even if there are no new values.
Hash partitioning is used to generate the RDDs with <code>numPartitions</code> partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd><dt class="param">numPartitions</dt><dd class="cmt"><p>Number of partitions of each RDD in the new DStream.</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.streaming.dstream.PairDStreamFunctions#updateStateByKey" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S])(implicitevidence$4:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" class="anchorToMember"></a><a id="updateStateByKey[S]((Seq[V],Option[S])=&gt;Option[S])(ClassTag[S]):DStream[(K,S)]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#updateStateByKey[S](updateFunc:(Seq[V],Option[S])=&gt;Option[S])(implicitevidence$4:scala.reflect.ClassTag[S]):org.apache.spark.streaming.dstream.DStream[(K,S)]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">updateStateByKey</span><span class="tparams">[<span name="S">S</span>]</span><span class="params">(<span name="updateFunc">updateFunc: (<span name="scala.Seq" class="extype">Seq</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.V" class="extype">V</span>], <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]) =&gt; <span name="scala.Option" class="extype">Option</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="params">(<span class="implicit">implicit </span><span name="arg0">arg0: <span name="scala.reflect.ClassTag" class="extype">ClassTag</span>[<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>]</span>)</span><span class="result">: <a href="DStream.html" name="org.apache.spark.streaming.dstream.DStream" id="org.apache.spark.streaming.dstream.DStream" class="extype">DStream</a>[(<span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.K" class="extype">K</span>, <span name="org.apache.spark.streaming.dstream.PairDStreamFunctions.updateStateByKey.S" class="extype">S</span>)]</span></span><p class="shortcomment cmt">Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.</p><div class="fullcomment"><div class="comment cmt"><p>Return a new "state" DStream where the state for each key is updated by applying
the given function on the previous state of the key and the new values of each key.
In every batch the updateFunc will be called for each state even if there are no new values.
Hash partitioning is used to generate the RDDs with Spark's default number of partitions.</p></div><dl class="paramcmts block"><dt class="tparam">S</dt><dd class="cmt"><p>State type</p></dd><dt class="param">updateFunc</dt><dd class="cmt"><p>State update function. If <code>this</code> function returns None, then
                  corresponding state key-value pair will be eliminated.</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long,x$2:Int):Unit" class="anchorToMember"></a><a id="wait(Long,Int):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#wait(x$1:Long,x$2:Int):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long):Unit" class="anchorToMember"></a><a id="wait(Long):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#wait(x$1:Long):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#wait():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li></ol></div><div class="values members"><h3>Deprecated Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#finalize" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="finalize():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/streaming/dstream/PairDStreamFunctions.html#finalize():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name deprecated" title="Deprecated: (Since version 9)">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="symbol">classOf[java.lang.Throwable]</span></span>)</span> <span class="name">@Deprecated</span> </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 9)</i></p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"><div name="java.io.Serializable" class="parent"><h3>Inherited from <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a></h3></div><div name="scala.AnyRef" class="parent"><h3>Inherited from <span name="scala.AnyRef" class="extype">AnyRef</span></h3></div><div name="scala.Any" class="parent"><h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3></div></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
