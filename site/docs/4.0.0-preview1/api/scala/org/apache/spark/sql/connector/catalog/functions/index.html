<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview1 ScalaDoc  - org.apache.spark.sql.connector.catalog.functions</title><meta content="Spark 4.0.0 - preview1 ScalaDoc - org.apache.spark.sql.connector.catalog.functions" name="description"/><meta content="Spark 4.0.0 preview1 ScalaDoc org.apache.spark.sql.connector.catalog.functions" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../../../index.js"></script><script type="text/javascript" src="../../../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview1 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.connector" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="connector" class="anchorToMember"></a><a id="connector:connector" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title=""><span class="name">connector</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.catalog" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="catalog" class="anchorToMember"></a><a id="catalog:catalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title=""><span class="name">catalog</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented7 current" name="org.apache.spark.sql.connector.catalog.functions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="functions" class="anchorToMember"></a><a id="functions:functions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">functions</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector.catalog" id="org.apache.spark.sql.connector.catalog" class="extype">catalog</a></dd></dl></div></li><li class="current-entities indented7"><span class="separator"></span> <a href="AggregateFunction.html" title="Interface for a function that produces a result value by aggregating over multiple input rows." class="trait"></a><a href="AggregateFunction.html" title="Interface for a function that produces a result value by aggregating over multiple input rows.">AggregateFunction</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="BoundFunction.html" title="Represents a function that is bound to an input type." class="trait"></a><a href="BoundFunction.html" title="Represents a function that is bound to an input type.">BoundFunction</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="Function.html" title="Base class for user-defined functions." class="trait"></a><a href="Function.html" title="Base class for user-defined functions.">Function</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="Reducer.html" title="A 'reducer' for output of user-defined functions." class="trait"></a><a href="Reducer.html" title="A 'reducer' for output of user-defined functions.">Reducer</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="ReducibleFunction.html" title="Base class for user-defined functions that can be 'reduced' on another function." class="trait"></a><a href="ReducibleFunction.html" title="Base class for user-defined functions that can be 'reduced' on another function.">ReducibleFunction</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="ScalarFunction.html" title="Interface for a function that produces a result value for each input row." class="trait"></a><a href="ScalarFunction.html" title="Interface for a function that produces a result value for each input row.">ScalarFunction</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="UnboundFunction.html" title="Represents a user-defined function that is not bound to input types." class="trait"></a><a href="UnboundFunction.html" title="Represents a user-defined function that is not bound to input types.">UnboundFunction</a></li><li class="indented7 " name="org.apache.spark.sql.connector.catalog.index" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="index" class="anchorToMember"></a><a id="index:index" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/index/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index/index.html" title=""><span class="name">index</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector.catalog" id="org.apache.spark.sql.connector.catalog" class="extype">catalog</a></dd></dl></div></li></ul></div></div><div id="content"><body class="package value"><div id="definition"><div class="big-circle package">p</div><p id="owner"><a href="../../../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="../../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a>.<a href="../index.html" name="org.apache.spark.sql.connector.catalog" id="org.apache.spark.sql.connector.catalog" class="extype">catalog</a></p><h1>functions<span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/index.html" title="Permalink"><i class="material-icons"></i></a></span></h1></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">functions</span></span></h4><div id="comment" class="fullcommenttop"></div><div id="template"><div id="allMembers"><div id="types" class="types members"><h3>Type Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.AggregateFunction" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="AggregateFunction[S&lt;:java.io.Serializable,R]extendsBoundFunction" class="anchorToMember"></a><a id="AggregateFunction[S&lt;:Serializable,R]:AggregateFunction[S,R]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/AggregateFunction.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="AggregateFunction.html" title="Interface for a function that produces a result value by aggregating over multiple input rows."><span class="name">AggregateFunction</span></a><span class="tparams">[<span name="S">S &lt;: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a></span>, <span name="R">R</span>]</span><span class="result"> extends <a href="BoundFunction.html" name="org.apache.spark.sql.connector.catalog.functions.BoundFunction" id="org.apache.spark.sql.connector.catalog.functions.BoundFunction" class="extype">BoundFunction</a></span></span><p class="shortcomment cmt">Interface for a function that produces a result value by aggregating over multiple input rows.</p><div class="fullcomment"><div class="comment cmt"><p>Interface for a function that produces a result value by aggregating over multiple input rows.</p><p>For each input row, Spark will call the <code><a href="AggregateFunction.html#update(state:S,input:org.apache.spark.sql.catalyst.InternalRow):S" name="org.apache.spark.sql.connector.catalog.functions.AggregateFunction#update" id="org.apache.spark.sql.connector.catalog.functions.AggregateFunction#update" class="extmbr">#update</a></code> method which should evaluate the row
and update the aggregation state. The JVM type of result values produced by
<code><a href="AggregateFunction.html#produceResult(state:S):R" name="org.apache.spark.sql.connector.catalog.functions.AggregateFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.AggregateFunction#produceResult" class="extmbr">#produceResult</a></code> must be the type used by Spark's
InternalRow API for the <code><span name="DataType" class="extype">SQL data type</span></code> returned by <code><span name="#resultType()" class="extype">#resultType()</span></code>.
Please refer to class documentation of <code><a href="ScalarFunction.html" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction" class="extype">ScalarFunction</a></code> for the mapping between
<code><span name="DataType" class="extype">DataType</span></code> and the JVM type.</p><p>All implementations must support partial aggregation by implementing merge so that Spark can
partially aggregate and shuffle intermediate results, instead of shuffling all rows for an
aggregate. This reduces the impact of data skew and the amount of data shuffled to produce the
result.</p><p>Intermediate aggregation state must be <code><span name="Serializable" class="extype">Serializable</span></code> so that state produced by parallel
tasks can be serialized, shuffled, and then merged to produce a final result.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.BoundFunction" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="BoundFunctionextendsFunction" class="anchorToMember"></a><a id="BoundFunction:BoundFunction" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/BoundFunction.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="BoundFunction.html" title="Represents a function that is bound to an input type."><span class="name">BoundFunction</span></a><span class="result"> extends <a href="Function.html" name="org.apache.spark.sql.connector.catalog.functions.Function" id="org.apache.spark.sql.connector.catalog.functions.Function" class="extype">Function</a></span></span><p class="shortcomment cmt">Represents a function that is bound to an input type.</p><div class="fullcomment"><div class="comment cmt"><p>Represents a function that is bound to an input type.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.Function" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="FunctionextendsSerializable" class="anchorToMember"></a><a id="Function:Function" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/Function.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="Function.html" title="Base class for user-defined functions."><span class="name">Function</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a></span></span><p class="shortcomment cmt">Base class for user-defined functions.</p><div class="fullcomment"><div class="comment cmt"><p>Base class for user-defined functions.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.Reducer" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="Reducer[I,O]extendsObject" class="anchorToMember"></a><a id="Reducer[I,O]:Reducer[I,O]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/Reducer.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="Reducer.html" title="A 'reducer' for output of user-defined functions."><span class="name">Reducer</span></a><span class="tparams">[<span name="I">I</span>, <span name="O">O</span>]</span><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">A 'reducer' for output of user-defined functions.</p><div class="fullcomment"><div class="comment cmt"><p>A 'reducer' for output of user-defined functions.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>4.0.0</p></dd><dt>See also</dt><dd><span class="cmt"><p>ReducibleFunction
A user defined function f_source(x) is 'reducible' on another user_defined function
f_target(x) if</p><ul><li> There exists a reducer function r(x) such that r(f_source(x)) = f_target(x) for
       all input x, or</li><li> More generally, there exists reducer functions r1(x) and r2(x) such that
       r1(f_source(x)) = r2(f_target(x)) for all input x.</li></ul></span></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.ReducibleFunction" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ReducibleFunction[I,O]extendsObject" class="anchorToMember"></a><a id="ReducibleFunction[I,O]:ReducibleFunction[I,O]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/ReducibleFunction.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="ReducibleFunction.html" title="Base class for user-defined functions that can be 'reduced' on another function."><span class="name">ReducibleFunction</span></a><span class="tparams">[<span name="I">I</span>, <span name="O">O</span>]</span><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">Base class for user-defined functions that can be 'reduced' on another function.</p><div class="fullcomment"><div class="comment cmt"><p>Base class for user-defined functions that can be 'reduced' on another function.</p><p>A function f_source(x) is 'reducible' on another function f_target(x) if</p><ul><li> There exists a reducer function r(x) such that r(f_source(x)) = f_target(x)
       for all input x, or</li><li> More generally, there exists reducer functions r1(x) and r2(x) such that
       r1(f_source(x)) = r2(f_target(x)) for all input x.</li></ul><p>Examples:</p><ul><li>Bucket functions where one side has reducer</li><li>f_source(x) = bucket(4, x)</li><li>f_target(x) = bucket(2, x)</li><li>r(x) = x % 2</li><li>Bucket functions where both sides have reducer</li><li>f_source(x) = bucket(16, x)</li><li>f_target(x) = bucket(12, x)</li><li>r1(x) = x % 4</li><li>r2(x) = x % 4</li><li>Date functions</li><li>f_source(x) = days(x)</li><li>f_target(x) = hours(x)</li><li>r(x) = x / 24</li></ul></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>4.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ScalarFunction[R]extendsBoundFunction" class="anchorToMember"></a><a id="ScalarFunction[R]:ScalarFunction[R]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/ScalarFunction.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="ScalarFunction.html" title="Interface for a function that produces a result value for each input row."><span class="name">ScalarFunction</span></a><span class="tparams">[<span name="R">R</span>]</span><span class="result"> extends <a href="BoundFunction.html" name="org.apache.spark.sql.connector.catalog.functions.BoundFunction" id="org.apache.spark.sql.connector.catalog.functions.BoundFunction" class="extype">BoundFunction</a></span></span><p class="shortcomment cmt">Interface for a function that produces a result value for each input row.</p><div class="fullcomment"><div class="comment cmt"><p>Interface for a function that produces a result value for each input row.</p><p>To evaluate each input row, Spark will first try to lookup and use a "magic method" (described
below) through Java reflection. If the method is not found, Spark will call
<code><span name="#produceResult(InternalRow)" class="extype">#produceResult(InternalRow)</span></code> as a fallback approach.</p><p>The JVM type of result values produced by this function must be the type used by Spark's
InternalRow API for the <code><span name="DataType" class="extype">SQL data type</span></code> returned by <code><span name="#resultType()" class="extype">#resultType()</span></code>.
The mapping between <code><span name="DataType" class="extype">DataType</span></code> and the corresponding JVM type is defined below.</p><h4>  Magic method  </h4><p><b>IMPORTANT</b>: the default implementation of <code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code> throws
<code><span name="UnsupportedOperationException" class="extype">UnsupportedOperationException</span></code>. Users must choose to either override this method, or
implement a magic method with name <code><span name="#MAGIC_METHOD_NAME" class="extype">#MAGIC_METHOD_NAME</span></code>, which takes individual parameters
instead of a <code><span name="InternalRow" class="extype">InternalRow</span></code>. The magic method approach is generally recommended because it
provides better performance over the default <code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code>, due to optimizations such
as whole-stage codegen, elimination of Java boxing, etc.</p><p>The type parameters for the magic method <b>must match</b> those returned from
<code><span name="BoundFunction#inputTypes()" class="extype">BoundFunction#inputTypes()</span></code>. Otherwise Spark will not be able to find the magic method.</p><p>In addition, for stateless Java functions, users can optionally define the
<code><span name="#MAGIC_METHOD_NAME" class="extype">#MAGIC_METHOD_NAME</span></code> as a static method, which further avoids certain runtime costs such
as Java dynamic dispatch.</p><p>For example, a scalar UDF for adding two integers can be defined as follow with the magic
method approach:</p><p><pre>
  public class IntegerAdd implements<code>ScalarFunction<Integer></code> {
    public DataType[] inputTypes() {
      return new DataType[] { DataTypes.IntegerType, DataTypes.IntegerType };
    }
    public int invoke(int left, int right) {
      return left + right;
    }
  }
</pre>
In the above, since <code><span name="#MAGIC_METHOD_NAME" class="extype">#MAGIC_METHOD_NAME</span></code> is defined, and also that it has
matching parameter types and return type, Spark will use it to evaluate inputs.</p><p>As another example, in the following:
<pre>
  public class IntegerAdd implements<code>ScalarFunction<Integer></code> {
    public DataType[] inputTypes() {
      return new DataType[] { DataTypes.IntegerType, DataTypes.IntegerType };
    }
    public static int invoke(int left, int right) {
      return left + right;
    }
    public Integer produceResult(InternalRow input) {
      return input.getInt(0) + input.getInt(1);
    }
  }
</pre></p><p>the class defines both the magic method and the <code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code>, and Spark will use
<code><span name="#MAGIC_METHOD_NAME" class="extype">#MAGIC_METHOD_NAME</span></code> over the <code><span name="#produceResult(InternalRow)" class="extype">#produceResult(InternalRow)</span></code> as it takes higher
precedence. Also note that the magic method is annotated as a static method in this case.</p><p>Resolution on magic method is done during query analysis, where Spark looks up the magic
method by first converting the actual input SQL data types to their corresponding Java types
following the mapping defined below, and then checking if there is a matching method from all the
declared methods in the UDF class, using method name and the Java types.</p><h4>  Handling of nullable primitive arguments  </h4><p>The handling of null primitive arguments is different between the magic method approach and
the <code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code> approach. With the former, whenever any of the method arguments meet
the following conditions:</p><ul><li>the argument is of primitive type</li><li>the argument is nullable</li><li>the value of the argument is null</li></ul><p>Spark will return null directly instead of calling the magic method. On the other hand, Spark
will pass null primitive arguments to <code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code> and it is user's responsibility to
handle them in the function implementation.</p><p>Because of the difference, if Spark users want to implement special handling of nulls for
nullable primitive arguments, they should override the <code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code> method instead
of using the magic method approach.</p><h4>  Spark data type to Java type mapping  </h4><p>The following are the mapping from <code><span name="DataType" class="extype">SQL data type</span></code> to Java type which is used
by Spark to infer parameter types for the magic methods as well as return value type for
<code><a href="ScalarFunction.html#produceResult(input:org.apache.spark.sql.catalyst.InternalRow):R" name="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" id="org.apache.spark.sql.connector.catalog.functions.ScalarFunction#produceResult" class="extmbr">#produceResult</a></code>:</p><ul><li><code><a href="../../../types/BooleanType.html" name="org.apache.spark.sql.types.BooleanType" id="org.apache.spark.sql.types.BooleanType" class="extype">org.apache.spark.sql.types.BooleanType</a></code>: <code>boolean</code></li><li><code><a href="../../../types/ByteType.html" name="org.apache.spark.sql.types.ByteType" id="org.apache.spark.sql.types.ByteType" class="extype">org.apache.spark.sql.types.ByteType</a></code>: <code>byte</code></li><li><code><a href="../../../types/ShortType.html" name="org.apache.spark.sql.types.ShortType" id="org.apache.spark.sql.types.ShortType" class="extype">org.apache.spark.sql.types.ShortType</a></code>: <code>short</code></li><li><code><a href="../../../types/IntegerType.html" name="org.apache.spark.sql.types.IntegerType" id="org.apache.spark.sql.types.IntegerType" class="extype">org.apache.spark.sql.types.IntegerType</a></code>: <code>int</code></li><li><code><a href="../../../types/LongType.html" name="org.apache.spark.sql.types.LongType" id="org.apache.spark.sql.types.LongType" class="extype">org.apache.spark.sql.types.LongType</a></code>: <code>long</code></li><li><code><a href="../../../types/FloatType.html" name="org.apache.spark.sql.types.FloatType" id="org.apache.spark.sql.types.FloatType" class="extype">org.apache.spark.sql.types.FloatType</a></code>: <code>float</code></li><li><code><a href="../../../types/DoubleType.html" name="org.apache.spark.sql.types.DoubleType" id="org.apache.spark.sql.types.DoubleType" class="extype">org.apache.spark.sql.types.DoubleType</a></code>: <code>double</code></li><li><code><a href="../../../types/StringType.html" name="org.apache.spark.sql.types.StringType" id="org.apache.spark.sql.types.StringType" class="extype">org.apache.spark.sql.types.StringType</a></code>:
      <code><span name="org.apache.spark.unsafe.types.UTF8String" class="extype">org.apache.spark.unsafe.types.UTF8String</span></code></li><li><code><a href="../../../types/DateType.html" name="org.apache.spark.sql.types.DateType" id="org.apache.spark.sql.types.DateType" class="extype">org.apache.spark.sql.types.DateType</a></code>: <code>int</code></li><li><code><a href="../../../types/TimestampType.html" name="org.apache.spark.sql.types.TimestampType" id="org.apache.spark.sql.types.TimestampType" class="extype">org.apache.spark.sql.types.TimestampType</a></code>: <code>long</code></li><li><code><a href="../../../types/BinaryType.html" name="org.apache.spark.sql.types.BinaryType" id="org.apache.spark.sql.types.BinaryType" class="extype">org.apache.spark.sql.types.BinaryType</a></code>: <code>byte[]</code></li><li><code><a href="../../../types/DayTimeIntervalType.html" name="org.apache.spark.sql.types.DayTimeIntervalType" id="org.apache.spark.sql.types.DayTimeIntervalType" class="extype">org.apache.spark.sql.types.DayTimeIntervalType</a></code>: <code>long</code></li><li><code><a href="../../../types/YearMonthIntervalType.html" name="org.apache.spark.sql.types.YearMonthIntervalType" id="org.apache.spark.sql.types.YearMonthIntervalType" class="extype">org.apache.spark.sql.types.YearMonthIntervalType</a></code>: <code>int</code></li><li><code><a href="../../../types/DecimalType.html" name="org.apache.spark.sql.types.DecimalType" id="org.apache.spark.sql.types.DecimalType" class="extype">org.apache.spark.sql.types.DecimalType</a></code>:
      <code><a href="../../../types/Decimal.html" name="org.apache.spark.sql.types.Decimal" id="org.apache.spark.sql.types.Decimal" class="extype">org.apache.spark.sql.types.Decimal</a></code></li><li><code><a href="../../../types/StructType.html" name="org.apache.spark.sql.types.StructType" id="org.apache.spark.sql.types.StructType" class="extype">org.apache.spark.sql.types.StructType</a></code>: <code><span name="InternalRow" class="extype">InternalRow</span></code></li><li><code><a href="../../../types/ArrayType.html" name="org.apache.spark.sql.types.ArrayType" id="org.apache.spark.sql.types.ArrayType" class="extype">org.apache.spark.sql.types.ArrayType</a></code>:
      <code><span name="org.apache.spark.sql.catalyst.util.ArrayData" class="extype">org.apache.spark.sql.catalyst.util.ArrayData</span></code></li><li><code><a href="../../../types/MapType.html" name="org.apache.spark.sql.types.MapType" id="org.apache.spark.sql.types.MapType" class="extype">org.apache.spark.sql.types.MapType</a></code>:
      <code><span name="org.apache.spark.sql.catalyst.util.MapData" class="extype">org.apache.spark.sql.catalyst.util.MapData</span></code></li></ul></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions.UnboundFunction" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="UnboundFunctionextendsFunction" class="anchorToMember"></a><a id="UnboundFunction:UnboundFunction" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/catalog/functions/UnboundFunction.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="UnboundFunction.html" title="Represents a user-defined function that is not bound to input types."><span class="name">UnboundFunction</span></a><span class="result"> extends <a href="Function.html" name="org.apache.spark.sql.connector.catalog.functions.Function" id="org.apache.spark.sql.connector.catalog.functions.Function" class="extype">Function</a></span></span><p class="shortcomment cmt">Represents a user-defined function that is not bound to input types.</p><div class="fullcomment"><div class="comment cmt"><p>Represents a user-defined function that is not bound to input types.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
