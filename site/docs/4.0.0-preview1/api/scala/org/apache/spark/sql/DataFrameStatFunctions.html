<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview1 ScalaDoc  - org.apache.spark.sql.DataFrameStatFunctions</title><meta content="Spark 4.0.0 - preview1 ScalaDoc - org.apache.spark.sql.DataFrameStatFunctions" name="description"/><meta content="Spark 4.0.0 preview1 ScalaDoc org.apache.spark.sql.DataFrameStatFunctions" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../lib/index.js"></script><script type="text/javascript" src="../../../../index.js"></script><script type="text/javascript" src="../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview1 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.api" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="api" class="anchorToMember"></a><a id="api:api" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/api/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="api/index.html" title="Contains API classes that are specific to a single language (i.e."><span class="name">api</span></a></span><p class="shortcomment cmt">Contains API classes that are specific to a single language (i.e.</p><div class="fullcomment"><div class="comment cmt"><p>Contains API classes that are specific to a single language (i.e. Java).
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.artifact" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="artifact" class="anchorToMember"></a><a id="artifact:artifact" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/artifact/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="artifact/index.html" title=""><span class="name">artifact</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.avro" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="avro" class="anchorToMember"></a><a id="avro:avro" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/avro/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="avro/index.html" title=""><span class="name">avro</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.catalog" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="catalog" class="anchorToMember"></a><a id="catalog:catalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/catalog/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="catalog/index.html" title=""><span class="name">catalog</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.catalyst" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="catalyst" class="anchorToMember"></a><a id="catalyst:catalyst" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/catalyst/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="catalyst/index.html" title=""><span class="name">catalyst</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.columnar" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="columnar" class="anchorToMember"></a><a id="columnar:columnar" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/columnar/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="columnar/index.html" title=""><span class="name">columnar</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.connector" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="connector" class="anchorToMember"></a><a id="connector:connector" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/connector/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="connector/index.html" title=""><span class="name">connector</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.expressions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="expressions" class="anchorToMember"></a><a id="expressions:expressions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/expressions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="expressions/index.html" title=""><span class="name">expressions</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.jdbc" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="jdbc" class="anchorToMember"></a><a id="jdbc:jdbc" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/jdbc/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="jdbc/index.html" title=""><span class="name">jdbc</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.sources" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sources" class="anchorToMember"></a><a id="sources:sources" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/sources/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="sources/index.html" title="A set of APIs for adding data sources to Spark SQL."><span class="name">sources</span></a></span><p class="shortcomment cmt">A set of APIs for adding data sources to Spark SQL.</p><div class="fullcomment"><div class="comment cmt"><p>A set of APIs for adding data sources to Spark SQL.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.streaming" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="streaming" class="anchorToMember"></a><a id="streaming:streaming" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="streaming/index.html" title=""><span class="name">streaming</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.types" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="types" class="anchorToMember"></a><a id="types:types" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/types/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="types/index.html" title="Contains a type system for attributes produced by relations, including complex types like structs, arrays and maps."><span class="name">types</span></a></span><p class="shortcomment cmt">Contains a type system for attributes produced by relations, including complex types like
structs, arrays and maps.</p><div class="fullcomment"><div class="comment cmt"><p>Contains a type system for attributes produced by relations, including complex types like
structs, arrays and maps.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.util" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="util" class="anchorToMember"></a><a id="util:util" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/util/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="util/index.html" title=""><span class="name">util</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.vectorized" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="vectorized" class="anchorToMember"></a><a id="vectorized:vectorized" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/vectorized/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="vectorized/index.html" title=""><span class="name">vectorized</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="current-entities indented4"><span class="separator"></span> <a href="AnalysisException.html" title="Thrown when a query fails to analyze, usually because the query itself is invalid." class="class"></a><a href="AnalysisException.html" title="Thrown when a query fails to analyze, usually because the query itself is invalid.">AnalysisException</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="Column.html" title="A column that will be computed based on the data in a DataFrame." class="class"></a><a href="Column.html" title="A column that will be computed based on the data in a DataFrame.">Column</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="ColumnName.html" title="A convenient class used for constructing schema." class="class"></a><a href="ColumnName.html" title="A convenient class used for constructing schema.">ColumnName</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="CreateTableWriter.html" title="Trait to restrict calls to create and replace operations." class="trait"></a><a href="CreateTableWriter.html" title="Trait to restrict calls to create and replace operations.">CreateTableWriter</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames." class="class"></a><a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames.">DataFrameNaFunctions</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g." class="class"></a><a href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g.">DataFrameReader</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="" title="Statistic functions for DataFrames." class="class"></a><a href="" title="Statistic functions for DataFrames.">DataFrameStatFunctions</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="DataFrameWriter.html" title="Interface used to write a Dataset to external storage systems (e.g." class="class"></a><a href="DataFrameWriter.html" title="Interface used to write a Dataset to external storage systems (e.g.">DataFrameWriter</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="DataFrameWriterV2.html" title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API." class="class"></a><a href="DataFrameWriterV2.html" title="Interface used to write a org.apache.spark.sql.Dataset to external storage using the v2 API.">DataFrameWriterV2</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="DataSourceRegistration.html" title="Functions for registering user-defined data sources." class="class"></a><a href="DataSourceRegistration.html" title="Functions for registering user-defined data sources.">DataSourceRegistration</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations." class="class"></a><a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations.">Dataset</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="DatasetHolder.html" title="A container for a Dataset, used for implicit conversions in Scala." class="class"></a><a href="DatasetHolder.html" title="A container for a Dataset, used for implicit conversions in Scala.">DatasetHolder</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="Encoder.html" title="Used to convert a JVM object of type T to and from the internal Spark SQL representation." class="trait"></a><a href="Encoder.html" title="Used to convert a JVM object of type T to and from the internal Spark SQL representation.">Encoder</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="Encoders$.html" title="Methods for creating an Encoder." class="object"></a><a href="Encoders$.html" title="Methods for creating an Encoder.">Encoders</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="ExperimentalMethods.html" title=":: Experimental :: Holder for experimental methods for the bravest." class="class"></a><a href="ExperimentalMethods.html" title=":: Experimental :: Holder for experimental methods for the bravest.">ExperimentalMethods</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="ExtendedExplainGenerator.html" title="A trait for a session extension to implement that provides addition explain plan information." class="trait"></a><a href="ExtendedExplainGenerator.html" title="A trait for a session extension to implement that provides addition explain plan information.">ExtendedExplainGenerator</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="ForeachWriter.html" title="The abstract class for writing custom logic to process data generated by a query." class="class"></a><a href="ForeachWriter.html" title="The abstract class for writing custom logic to process data generated by a query.">ForeachWriter</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key." class="class"></a><a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key.">KeyValueGroupedDataset</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="LowPrioritySQLImplicits.html" title="Lower priority implicit methods for converting Scala objects into Datasets." class="trait"></a><a href="LowPrioritySQLImplicits.html" title="Lower priority implicit methods for converting Scala objects into Datasets.">LowPrioritySQLImplicits</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="MergeIntoWriter.html" title="MergeIntoWriter provides methods to define and execute merge actions based on specified conditions." class="class"></a><a href="MergeIntoWriter.html" title="MergeIntoWriter provides methods to define and execute merge actions based on specified conditions.">MergeIntoWriter</a></li><li class="current-entities indented4"><a href="Observation$.html" title="(Scala-specific) Create instances of Observation via Scala apply." class="object"></a> <a href="Observation.html" title="Helper class to simplify usage of Dataset.observe(String, Column, Column*):" class="class"></a><a href="Observation.html" title="Helper class to simplify usage of Dataset.observe(String, Column, Column*):">Observation</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="ObservationBase.html" title="Helper class to simplify usage of Dataset.observe(String, Column, Column*):" class="class"></a><a href="ObservationBase.html" title="Helper class to simplify usage of Dataset.observe(String, Column, Column*):">ObservationBase</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)." class="class"></a><a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot).">RelationalGroupedDataset</a></li><li class="current-entities indented4"><a href="Row$.html" title="" class="object"></a> <a href="Row.html" title="Represents one row of output from a relational operator." class="trait"></a><a href="Row.html" title="Represents one row of output from a relational operator.">Row</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="RowFactory.html" title="A factory class used to construct Row objects." class="class"></a><a href="RowFactory.html" title="A factory class used to construct Row objects.">RowFactory</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="RuntimeConfig.html" title="Runtime configuration interface for Spark." class="class"></a><a href="RuntimeConfig.html" title="Runtime configuration interface for Spark.">RuntimeConfig</a></li><li class="current-entities indented4"><a href="SQLContext$.html" title="This SQLContext object contains utility functions to create a singleton SQLContext instance, or to get the created SQLContext instance." class="object"></a> <a href="SQLContext.html" title="The entry point for working with structured data (rows and columns) in Spark 1.x." class="class"></a><a href="SQLContext.html" title="The entry point for working with structured data (rows and columns) in Spark 1.x.">SQLContext</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="SQLImplicits.html" title="A collection of implicit methods for converting common Scala objects into Datasets." class="class"></a><a href="SQLImplicits.html" title="A collection of implicit methods for converting common Scala objects into Datasets.">SQLImplicits</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="SaveMode.html" title="SaveMode is used to specify the expected behavior of saving a DataFrame to a data source." class="class"></a><a href="SaveMode.html" title="SaveMode is used to specify the expected behavior of saving a DataFrame to a data source.">SaveMode</a></li><li class="current-entities indented4"><a href="SparkSession$.html" title="" class="object"></a> <a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API." class="class"></a><a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API.">SparkSession</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="SparkSessionExtensions.html" title=":: Experimental :: Holder for injection points to the SparkSession." class="class"></a><a href="SparkSessionExtensions.html" title=":: Experimental :: Holder for injection points to the SparkSession.">SparkSessionExtensions</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="SparkSessionExtensionsProvider.html" title=":: Unstable ::" class="trait"></a><a href="SparkSessionExtensionsProvider.html" title=":: Unstable ::">SparkSessionExtensionsProvider</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="TypedColumn.html" title="A Column where an Encoder has been given for the expected input and return type." class="class"></a><a href="TypedColumn.html" title="A Column where an Encoder has been given for the expected input and return type.">TypedColumn</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="UDFRegistration.html" title="Functions for registering user-defined functions." class="class"></a><a href="UDFRegistration.html" title="Functions for registering user-defined functions.">UDFRegistration</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="UDTFRegistration.html" title="Functions for registering user-defined table functions." class="class"></a><a href="UDTFRegistration.html" title="Functions for registering user-defined table functions.">UDTFRegistration</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="WhenMatched.html" title="A class for defining actions to be taken when matching rows in a DataFrame during a merge operation." class="class"></a><a href="WhenMatched.html" title="A class for defining actions to be taken when matching rows in a DataFrame during a merge operation.">WhenMatched</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="WhenNotMatched.html" title="A class for defining actions to be taken when no matching rows are found in a DataFrame during a merge operation." class="class"></a><a href="WhenNotMatched.html" title="A class for defining actions to be taken when no matching rows are found in a DataFrame during a merge operation.">WhenNotMatched</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="WhenNotMatchedBySource.html" title="A class for defining actions to be performed when there is no match by source during a merge operation in a MergeIntoWriter." class="class"></a><a href="WhenNotMatchedBySource.html" title="A class for defining actions to be performed when there is no match by source during a merge operation in a MergeIntoWriter.">WhenNotMatchedBySource</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="WriteConfigMethods.html" title="Configuration methods common to create/replace operations and insert/overwrite operations." class="trait"></a><a href="WriteConfigMethods.html" title="Configuration methods common to create/replace operations and insert/overwrite operations.">WriteConfigMethods</a></li><li class="current-entities indented4"><span class="separator"></span> <a href="functions$.html" title="Commonly used functions available for DataFrame operations." class="object"></a><a href="functions$.html" title="Commonly used functions available for DataFrame operations.">functions</a></li></ul></div></div><div id="content"><body class="class type"><div id="definition"><div class="big-circle class">c</div><p id="owner"><a href="../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></p><h1>DataFrameStatFunctions<span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html" title="Permalink"><i class="material-icons"></i></a></span></h1><h3><span class="morelinks"></span></h3></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier">final </span> <span class="kind">class</span></span> <span class="symbol"><span class="name">DataFrameStatFunctions</span><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span></h4><div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Statistic functions for <code>DataFrame</code>s.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Stable</span><span class="args">()</span> </dd><dt>Source</dt><dd><a href="https://github.com/apache/spark/tree/v4.0.0-preview1/sql/core/src/main/scala/org/apache/spark/sql/DataFrameStatFunctions.scala" target="_blank">DataFrameStatFunctions.scala</a></dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl><div class="toggleContainer"><div class="toggle block"><span>Linear Supertypes</span><div class="superTypes hiddenContent"><span name="scala.AnyRef" class="extype">AnyRef</span>, <span name="scala.Any" class="extype">Any</span></div></div></div></div><div id="mbrsel"><div class="toggle"></div><div id="memberfilter"><i class="material-icons arrow"></i><span class="input"><input placeholder="Filter all members" id="mbrsel-input" type="text" accesskey="/"/></span><i class="clear material-icons"></i></div><div id="filterby"><div id="order"><span class="filtertype">Ordering</span><ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By Inheritance</span></li></ol></div><div class="ancestors"><span class="filtertype">Inherited<br/></span><ol id="linearization"><li class="in" name="org.apache.spark.sql.DataFrameStatFunctions"><span>DataFrameStatFunctions</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li></ol></div><div class="ancestors"><span class="filtertype"></span><ol><li class="hideall out"><span>Hide All</span></li><li class="showall in"><span>Show All</span></li></ol></div><div id="visbl"><span class="filtertype">Visibility</span><ol><li class="public in"><span>Public</span></li><li class="protected out"><span>Protected</span></li></ol></div></div></div><div id="template"><div id="allMembers"><div class="values members"><h3>Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#!=" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="!=(x$1:Any):Boolean" class="anchorToMember"></a><a id="!=(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#!=(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef###" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="##:Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html###:Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $hash$hash">##</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#==" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="==(x$1:Any):Boolean" class="anchorToMember"></a><a id="==(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#==(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#approxQuantile" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="approxQuantile(cols:Array[String],probabilities:Array[Double],relativeError:Double):Array[Array[Double]]" class="anchorToMember"></a><a id="approxQuantile(Array[String],Array[Double],Double):Array[Array[Double]]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#approxQuantile(cols:Array[String],probabilities:Array[Double],relativeError:Double):Array[Array[Double]]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">approxQuantile</span><span class="params">(<span name="cols">cols: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="probabilities">probabilities: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]</span>, <span name="relativeError">relativeError: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]]</span></span><p class="shortcomment cmt">Calculates the approximate quantiles of numerical columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the approximate quantiles of numerical columns of a DataFrame.</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>the names of the numerical columns</p></dd><dt class="param">probabilities</dt><dd class="cmt"><p>a list of quantile probabilities
  Each number must belong to [0, 1].
  For example 0 is the minimum, 0.5 is the median, 1 is the maximum.</p></dd><dt class="param">relativeError</dt><dd class="cmt"><p>The relative target precision to achieve (greater than or equal to 0).
  If set to zero, the exact quantiles are computed, which could be very expensive.
  Note that values greater than 1 are accepted but give the same result as 1.</p></dd><dt>returns</dt><dd class="cmt"><p>the approximate quantiles at the given probabilities of each column</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.2.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>null and NaN values will be ignored in numerical columns before calculation. For
  columns only containing null or NaN values, an empty array is returned.</p></span></dd><dt>See also</dt><dd><span class="cmt"><p><code>approxQuantile(col:Str* approxQuantile)</code> for detailed description.</p></span></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#approxQuantile" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="approxQuantile(col:String,probabilities:Array[Double],relativeError:Double):Array[Double]" class="anchorToMember"></a><a id="approxQuantile(String,Array[Double],Double):Array[Double]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#approxQuantile(col:String,probabilities:Array[Double],relativeError:Double):Array[Double]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">approxQuantile</span><span class="params">(<span name="col">col: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="probabilities">probabilities: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]</span>, <span name="relativeError">relativeError: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]</span></span><p class="shortcomment cmt">Calculates the approximate quantiles of a numerical column of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the approximate quantiles of a numerical column of a DataFrame.</p><p>The result of this algorithm has the following deterministic bound:
If the DataFrame has N elements and if we request the quantile at probability <code>p</code> up to error
<code>err</code>, then the algorithm will return a sample <code>x</code> from the DataFrame so that the *exact* rank
of <code>x</code> is close to (p * N).
More precisely,</p><pre>floor((p - err) * N) &lt;= rank(x) &lt;= ceil((p + err) * N)</pre><p>This method implements a variation of the Greenwald-Khanna algorithm (with some speed
optimizations).
The algorithm was first present in <a href="https://doi.org/10.1145/375663.375670">
Space-efficient Online Computation of Quantile Summaries</a> by Greenwald and Khanna.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>the name of the numerical column</p></dd><dt class="param">probabilities</dt><dd class="cmt"><p>a list of quantile probabilities
  Each number must belong to [0, 1].
  For example 0 is the minimum, 0.5 is the median, 1 is the maximum.</p></dd><dt class="param">relativeError</dt><dd class="cmt"><p>The relative target precision to achieve (greater than or equal to 0).
  If set to zero, the exact quantiles are computed, which could be very expensive.
  Note that values greater than 1 are accepted but give the same result as 1.</p></dd><dt>returns</dt><dd class="cmt"><p>the approximate quantiles at the given probabilities</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>null and NaN values will be removed from the numerical column before calculation. If
  the dataframe is empty or the column only contains null or NaN, an empty array is returned.</p></span></dd></dl></div></li><li class="indented0 " name="scala.Any#asInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="asInstanceOf[T0]:T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#asInstanceOf[T0]:T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Any.asInstanceOf.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(Column,Long,Long):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="col">col: <a href="Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="numBits">numBits: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>expected number of items which will be put into the filter.</p></dd><dt class="param">numBits</dt><dd class="cmt"><p>expected number of bits of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(colName:String,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(String,Long,Long):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(colName:String,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="numBits">numBits: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>name of the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>expected number of items which will be put into the filter.</p></dd><dt class="param">numBits</dt><dd class="cmt"><p>expected number of bits of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(Column,Long,Double):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="col">col: <a href="Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="fpp">fpp: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>expected number of items which will be put into the filter.</p></dd><dt class="param">fpp</dt><dd class="cmt"><p>expected false positive probability of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(colName:String,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(String,Long,Double):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#bloomFilter(colName:String,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="fpp">fpp: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>name of the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>expected number of items which will be put into the filter.</p></dd><dt class="param">fpp</dt><dd class="cmt"><p>expected false positive probability of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#clone" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="clone():Object" class="anchorToMember"></a><a id="clone():AnyRef" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#clone():Object" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">clone</span><span class="params">()</span><span class="result">: <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.CloneNotSupportedException]</span></span>)</span> <span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#corr" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="corr(col1:String,col2:String):Double" class="anchorToMember"></a><a id="corr(String,String):Double" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#corr(col1:String,col2:String):Double" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">corr</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Double" class="extype">Double</span></span></span><p class="shortcomment cmt">Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>the name of the column</p></dd><dt class="param">col2</dt><dd class="cmt"><p>the name of the column to calculate the correlation against</p></dd><dt>returns</dt><dd class="cmt"><p>The Pearson Correlation Coefficient as a Double.</p><pre><span class="kw">val</span> df = sc.parallelize(<span class="num">0</span> until <span class="num">10</span>).toDF(<span class="lit">"id"</span>).withColumn(<span class="lit">"rand1"</span>, rand(seed=<span class="num">10</span>))
  .withColumn(<span class="lit">"rand2"</span>, rand(seed=<span class="num">27</span>))
df.stat.corr(<span class="lit">"rand1"</span>, <span class="lit">"rand2"</span>, <span class="lit">"pearson"</span>)
res1: <span class="std">Double</span> = <span class="num">0.613</span>...</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#corr" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="corr(col1:String,col2:String,method:String):Double" class="anchorToMember"></a><a id="corr(String,String,String):Double" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#corr(col1:String,col2:String,method:String):Double" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">corr</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="method">method: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Double" class="extype">Double</span></span></span><p class="shortcomment cmt">Calculates the correlation of two columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the correlation of two columns of a DataFrame. Currently only supports the Pearson
Correlation Coefficient. For Spearman Correlation, consider using RDD methods found in
MLlib's Statistics.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>the name of the column</p></dd><dt class="param">col2</dt><dd class="cmt"><p>the name of the column to calculate the correlation against</p></dd><dt>returns</dt><dd class="cmt"><p>The Pearson Correlation Coefficient as a Double.</p><pre><span class="kw">val</span> df = sc.parallelize(<span class="num">0</span> until <span class="num">10</span>).toDF(<span class="lit">"id"</span>).withColumn(<span class="lit">"rand1"</span>, rand(seed=<span class="num">10</span>))
  .withColumn(<span class="lit">"rand2"</span>, rand(seed=<span class="num">27</span>))
df.stat.corr(<span class="lit">"rand1"</span>, <span class="lit">"rand2"</span>)
res1: <span class="std">Double</span> = <span class="num">0.613</span>...</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(col:org.apache.spark.sql.Column,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(Column,Double,Double,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(col:org.apache.spark.sql.Column,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="col">col: <a href="Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="eps">eps: <span name="scala.Double" class="extype">Double</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>the column over which the sketch is built</p></dd><dt class="param">eps</dt><dd class="cmt"><p>relative error of the sketch</p></dd><dt class="param">confidence</dt><dd class="cmt"><p>confidence of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(col:org.apache.spark.sql.Column,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(Column,Int,Int,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(col:org.apache.spark.sql.Column,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="col">col: <a href="Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="depth">depth: <span name="scala.Int" class="extype">Int</span></span>, <span name="width">width: <span name="scala.Int" class="extype">Int</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>the column over which the sketch is built</p></dd><dt class="param">depth</dt><dd class="cmt"><p>depth of the sketch</p></dd><dt class="param">width</dt><dd class="cmt"><p>width of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(colName:String,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(String,Double,Double,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(colName:String,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="eps">eps: <span name="scala.Double" class="extype">Double</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>name of the column over which the sketch is built</p></dd><dt class="param">eps</dt><dd class="cmt"><p>relative error of the sketch</p></dd><dt class="param">confidence</dt><dd class="cmt"><p>confidence of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(colName:String,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(String,Int,Int,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#countMinSketch(colName:String,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="depth">depth: <span name="scala.Int" class="extype">Int</span></span>, <span name="width">width: <span name="scala.Int" class="extype">Int</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>name of the column over which the sketch is built</p></dd><dt class="param">depth</dt><dd class="cmt"><p>depth of the sketch</p></dd><dt class="param">width</dt><dd class="cmt"><p>width of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#cov" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="cov(col1:String,col2:String):Double" class="anchorToMember"></a><a id="cov(String,String):Double" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#cov(col1:String,col2:String):Double" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">cov</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Double" class="extype">Double</span></span></span><p class="shortcomment cmt">Calculate the sample covariance of two numerical columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculate the sample covariance of two numerical columns of a DataFrame.</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>the name of the first column</p></dd><dt class="param">col2</dt><dd class="cmt"><p>the name of the second column</p></dd><dt>returns</dt><dd class="cmt"><p>the covariance of the two columns.</p><pre><span class="kw">val</span> df = sc.parallelize(<span class="num">0</span> until <span class="num">10</span>).toDF(<span class="lit">"id"</span>).withColumn(<span class="lit">"rand1"</span>, rand(seed=<span class="num">10</span>))
  .withColumn(<span class="lit">"rand2"</span>, rand(seed=<span class="num">27</span>))
df.stat.cov(<span class="lit">"rand1"</span>, <span class="lit">"rand2"</span>)
res1: <span class="std">Double</span> = <span class="num">0.065</span>...</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#crosstab" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="crosstab(col1:String,col2:String):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="crosstab(String,String):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#crosstab(col1:String,col2:String):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">crosstab</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">Computes a pair-wise frequency table of the given columns.</p><div class="fullcomment"><div class="comment cmt"><p>Computes a pair-wise frequency table of the given columns. Also known as a contingency table.
The first column of each row will be the distinct values of <code>col1</code> and the column names will
be the distinct values of <code>col2</code>. The name of the first column will be <code>col1_col2</code>. Counts
will be returned as <code>Long</code>s. Pairs that have no occurrences will have zero as their counts.
Null elements will be replaced by "null", and back ticks will be dropped from elements if they
exist.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>The name of the first column. Distinct items will make the first item of
            each row.</p></dd><dt class="param">col2</dt><dd class="cmt"><p>The name of the second column. Distinct items will make the column names
            of the DataFrame.</p></dd><dt>returns</dt><dd class="cmt"><p>A DataFrame containing for the contingency table.</p><pre><span class="kw">val</span> df = spark.createDataFrame(<span class="std">Seq</span>((<span class="num">1</span>, <span class="num">1</span>), (<span class="num">1</span>, <span class="num">2</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">3</span>), (<span class="num">3</span>, <span class="num">2</span>), (<span class="num">3</span>, <span class="num">3</span>)))
  .toDF(<span class="lit">"key"</span>, <span class="lit">"value"</span>)
<span class="kw">val</span> ct = df.stat.crosstab(<span class="lit">"key"</span>, <span class="lit">"value"</span>)
ct.show()
+---------+---+---+---+
|key_value|  <span class="num">1</span>|  <span class="num">2</span>|  <span class="num">3</span>|
+---------+---+---+---+
|        <span class="num">2</span>|  <span class="num">2</span>|  <span class="num">0</span>|  <span class="num">1</span>|
|        <span class="num">1</span>|  <span class="num">1</span>|  <span class="num">1</span>|  <span class="num">0</span>|
|        <span class="num">3</span>|  <span class="num">0</span>|  <span class="num">1</span>|  <span class="num">1</span>|
+---------+---+---+---+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#eq" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="eq(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="eq(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#eq(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#equals" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="equals(x$1:Object):Boolean" class="anchorToMember"></a><a id="equals(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#equals(x$1:Object):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Seq[String]):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="freqItems(Seq[String]):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(cols:Seq[String]):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Seq" class="extype">Seq</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">(Scala-specific) Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
frequent element count algorithm described in
<a href="https://doi.org/10.1145/762471.762473">here</a>, proposed by Karp, Schenker,
and Papadimitriou.
Uses a <code>default</code> support of 1%.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>the names of the columns to search frequent items in.</p></dd><dt>returns</dt><dd class="cmt"><p>A Local DataFrame with the Array of frequent items for each column.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Seq[String],support:Double):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="freqItems(Seq[String],Double):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(cols:Seq[String],support:Double):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Seq" class="extype">Seq</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="support">support: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">(Scala-specific) Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
frequent element count algorithm described in
<a href="https://doi.org/10.1145/762471.762473">here</a>, proposed by Karp, Schenker,
and Papadimitriou.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>the names of the columns to search frequent items in.</p></dd><dt>returns</dt><dd class="cmt"><p>A Local DataFrame with the Array of frequent items for each column.</p><pre><span class="kw">val</span> rows = <span class="std">Seq</span>.tabulate(<span class="num">100</span>) { i <span class="kw">=&gt;</span>
  <span class="kw">if</span> (i % <span class="num">2</span> == <span class="num">0</span>) (<span class="num">1</span>, -<span class="num">1.0</span>) <span class="kw">else</span> (i, i * -<span class="num">1.0</span>)
}
<span class="kw">val</span> df = spark.createDataFrame(rows).toDF(<span class="lit">"a"</span>, <span class="lit">"b"</span>)
<span class="cmt">// find the items with a frequency greater than 0.4 (observed 40% of the time) for columns</span>
<span class="cmt">// "a" and "b"</span>
<span class="kw">val</span> freqSingles = df.stat.freqItems(<span class="std">Seq</span>(<span class="lit">"a"</span>, <span class="lit">"b"</span>), <span class="num">0.4</span>)
freqSingles.show()
+-----------+-------------+
|a_freqItems|  b_freqItems|
+-----------+-------------+
|    [<span class="num">1</span>, <span class="num">99</span>]|[-<span class="num">1.0</span>, -<span class="num">99.0</span>]|
+-----------+-------------+
<span class="cmt">// find the pair of items with a frequency greater than 0.1 in columns "a" and "b"</span>
<span class="kw">val</span> pairDf = df.select(struct(<span class="lit">"a"</span>, <span class="lit">"b"</span>).as(<span class="lit">"a-b"</span>))
<span class="kw">val</span> freqPairs = pairDf.stat.freqItems(<span class="std">Seq</span>(<span class="lit">"a-b"</span>), <span class="num">0.1</span>)
freqPairs.select(explode($<span class="lit">"a-b_freqItems"</span>).as(<span class="lit">"freq_ab"</span>)).show()
+----------+
|   freq_ab|
+----------+
|  [<span class="num">1</span>,-<span class="num">1.0</span>]|
|   ...    |
+----------+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Array[String]):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="freqItems(Array[String]):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(cols:Array[String]):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>Finding frequent items for columns, possibly with false positives. Using the
frequent element count algorithm described in
<a href="https://doi.org/10.1145/762471.762473">here</a>, proposed by Karp,
Schenker, and Papadimitriou.
Uses a <code>default</code> support of 1%.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>the names of the columns to search frequent items in.</p></dd><dt>returns</dt><dd class="cmt"><p>A Local DataFrame with the Array of frequent items for each column.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Array[String],support:Double):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="freqItems(Array[String],Double):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#freqItems(cols:Array[String],support:Double):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="support">support: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>Finding frequent items for columns, possibly with false positives. Using the
frequent element count algorithm described in
<a href="https://doi.org/10.1145/762471.762473">here</a>, proposed by Karp,
Schenker, and Papadimitriou.
The <code>support</code> should be greater than 1e-4.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>the names of the columns to search frequent items in.</p></dd><dt class="param">support</dt><dd class="cmt"><p>The minimum frequency for an item to be considered <code>frequent</code>. Should be greater
               than 1e-4.</p></dd><dt>returns</dt><dd class="cmt"><p>A Local DataFrame with the Array of frequent items for each column.</p><pre><span class="kw">val</span> rows = <span class="std">Seq</span>.tabulate(<span class="num">100</span>) { i <span class="kw">=&gt;</span>
  <span class="kw">if</span> (i % <span class="num">2</span> == <span class="num">0</span>) (<span class="num">1</span>, -<span class="num">1.0</span>) <span class="kw">else</span> (i, i * -<span class="num">1.0</span>)
}
<span class="kw">val</span> df = spark.createDataFrame(rows).toDF(<span class="lit">"a"</span>, <span class="lit">"b"</span>)
<span class="cmt">// find the items with a frequency greater than 0.4 (observed 40% of the time) for columns</span>
<span class="cmt">// "a" and "b"</span>
<span class="kw">val</span> freqSingles = df.stat.freqItems(<span class="std">Array</span>(<span class="lit">"a"</span>, <span class="lit">"b"</span>), <span class="num">0.4</span>)
freqSingles.show()
+-----------+-------------+
|a_freqItems|  b_freqItems|
+-----------+-------------+
|    [<span class="num">1</span>, <span class="num">99</span>]|[-<span class="num">1.0</span>, -<span class="num">99.0</span>]|
+-----------+-------------+
<span class="cmt">// find the pair of items with a frequency greater than 0.1 in columns "a" and "b"</span>
<span class="kw">val</span> pairDf = df.select(struct(<span class="lit">"a"</span>, <span class="lit">"b"</span>).as(<span class="lit">"a-b"</span>))
<span class="kw">val</span> freqPairs = pairDf.stat.freqItems(<span class="std">Array</span>(<span class="lit">"a-b"</span>), <span class="num">0.1</span>)
freqPairs.select(explode($<span class="lit">"a-b_freqItems"</span>).as(<span class="lit">"freq_ab"</span>)).show()
+----------+
|   freq_ab|
+----------+
|  [<span class="num">1</span>,-<span class="num">1.0</span>]|
|   ...    |
+----------+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#getClass" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="getClass():Class[_]" class="anchorToMember"></a><a id="getClass():Class[_&lt;:AnyRef]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#getClass():Class[_]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">getClass</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html#java.lang.Class" name="java.lang.Class" id="java.lang.Class" class="extype">Class</a>[_ &lt;: <span name="scala.AnyRef" class="extype">AnyRef</span>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#hashCode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="hashCode():Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#hashCode():Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.Any#isInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="isInstanceOf[T0]:Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#isInstanceOf[T0]:Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#ne" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ne(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="ne(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#ne(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notify" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notify():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#notify():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notifyAll" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notifyAll():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#notifyAll():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:org.apache.spark.sql.Column,fractions:java.util.Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="sampleBy[T](Column,Map[T,Double],Long):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy[T](col:org.apache.spark.sql.Column,fractions:java.util.Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <a href="Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="fractions">fractions: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html#java.util.Map" name="java.util.Map" id="java.util.Map" class="extype">Map</a>[<span name="org.apache.spark.sql.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Double.html#java.lang.Double" name="java.lang.Double" id="java.lang.Double" class="extype">Double</a>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">(Java-specific) Returns a stratified sample without replacement based on the fraction given
on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>(Java-specific) Returns a stratified sample without replacement based on the fraction given
on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>sampling fraction for each stratum. If a stratum is not specified, we treat
                 its fraction as zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a new <code>DataFrame</code> that represents the stratified sample</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:org.apache.spark.sql.Column,fractions:Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="sampleBy[T](Column,Map[T,Double],Long):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy[T](col:org.apache.spark.sql.Column,fractions:Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <a href="Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="fractions">fractions: <span name="scala.Predef.Map" class="extype">Map</span>[<span name="org.apache.spark.sql.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <span name="scala.Double" class="extype">Double</span>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">Returns a stratified sample without replacement based on the fraction given on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a stratified sample without replacement based on the fraction given on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>sampling fraction for each stratum. If a stratum is not specified, we treat
                 its fraction as zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a new <code>DataFrame</code> that represents the stratified sample
The stratified sample can be performed over multiple columns:</p><pre><span class="kw">import</span> org.apache.spark.sql.Row
<span class="kw">import</span> org.apache.spark.sql.functions.struct

<span class="kw">val</span> df = spark.createDataFrame(<span class="std">Seq</span>((<span class="lit">"Bob"</span>, <span class="num">17</span>), (<span class="lit">"Alice"</span>, <span class="num">10</span>), (<span class="lit">"Nico"</span>, <span class="num">8</span>), (<span class="lit">"Bob"</span>, <span class="num">17</span>),
  (<span class="lit">"Alice"</span>, <span class="num">10</span>))).toDF(<span class="lit">"name"</span>, <span class="lit">"age"</span>)
<span class="kw">val</span> fractions = <span class="std">Map</span>(Row(<span class="lit">"Alice"</span>, <span class="num">10</span>) -&gt; <span class="num">0.3</span>, Row(<span class="lit">"Nico"</span>, <span class="num">8</span>) -&gt; <span class="num">1.0</span>)
df.stat.sampleBy(struct($<span class="lit">"name"</span>, $<span class="lit">"age"</span>), fractions, <span class="num">36</span>L).show()
+-----+---+
| name|age|
+-----+---+
| Nico|  <span class="num">8</span>|
|Alice| <span class="num">10</span>|
+-----+---+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:String,fractions:java.util.Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="sampleBy[T](String,Map[T,Double],Long):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy[T](col:String,fractions:java.util.Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="fractions">fractions: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html#java.util.Map" name="java.util.Map" id="java.util.Map" class="extype">Map</a>[<span name="org.apache.spark.sql.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Double.html#java.lang.Double" name="java.lang.Double" id="java.lang.Double" class="extype">Double</a>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">Returns a stratified sample without replacement based on the fraction given on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a stratified sample without replacement based on the fraction given on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>sampling fraction for each stratum. If a stratum is not specified, we treat
                 its fraction as zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a new <code>DataFrame</code> that represents the stratified sample</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.5.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:String,fractions:Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" class="anchorToMember"></a><a id="sampleBy[T](String,Map[T,Double],Long):DataFrame" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#sampleBy[T](col:String,fractions:Map[T,Double],seed:Long):org.apache.spark.sql.DataFrame" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="fractions">fractions: <span name="scala.Predef.Map" class="extype">Map</span>[<span name="org.apache.spark.sql.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <span name="scala.Double" class="extype">Double</span>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="index.html#DataFrame=org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]" name="org.apache.spark.sql.DataFrame" id="org.apache.spark.sql.DataFrame" class="extmbr">DataFrame</a></span></span><p class="shortcomment cmt">Returns a stratified sample without replacement based on the fraction given on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a stratified sample without replacement based on the fraction given on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>sampling fraction for each stratum. If a stratum is not specified, we treat
                 its fraction as zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>random seed</p></dd><dt>returns</dt><dd class="cmt"><p>a new <code>DataFrame</code> that represents the stratified sample</p><pre><span class="kw">val</span> df = spark.createDataFrame(<span class="std">Seq</span>((<span class="num">1</span>, <span class="num">1</span>), (<span class="num">1</span>, <span class="num">2</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">3</span>), (<span class="num">3</span>, <span class="num">2</span>),
  (<span class="num">3</span>, <span class="num">3</span>))).toDF(<span class="lit">"key"</span>, <span class="lit">"value"</span>)
<span class="kw">val</span> fractions = <span class="std">Map</span>(<span class="num">1</span> -&gt; <span class="num">1.0</span>, <span class="num">3</span> -&gt; <span class="num">0.5</span>)
df.stat.sampleBy(<span class="lit">"key"</span>, fractions, <span class="num">36</span>L).show()
+---+-----+
|key|value|
+---+-----+
|  <span class="num">1</span>|    <span class="num">1</span>|
|  <span class="num">1</span>|    <span class="num">2</span>|
|  <span class="num">3</span>|    <span class="num">2</span>|
+---+-----+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.5.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#synchronized" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="synchronized[T0](x$1:=&gt;T0):T0" class="anchorToMember"></a><a id="synchronized[T0](=&gt;T0):T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#synchronized[T0](x$1:=&gt;T0):T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: =&gt; <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span>)</span><span class="result">: <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#toString" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="toString():String" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#toString():String" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">toString</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html#java.lang.String" name="java.lang.String" id="java.lang.String" class="extype">String</a></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long,x$2:Int):Unit" class="anchorToMember"></a><a id="wait(Long,Int):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#wait(x$1:Long,x$2:Int):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long):Unit" class="anchorToMember"></a><a id="wait(Long):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#wait(x$1:Long):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#wait():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li></ol></div><div class="values members"><h3>Deprecated Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#finalize" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="finalize():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../org/apache/spark/sql/DataFrameStatFunctions.html#finalize():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name deprecated" title="Deprecated: (Since version 9)">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="symbol">classOf[java.lang.Throwable]</span></span>)</span> <span class="name">@Deprecated</span> </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 9)</i></p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"><div name="scala.AnyRef" class="parent"><h3>Inherited from <span name="scala.AnyRef" class="extype">AnyRef</span></h3></div><div name="scala.Any" class="parent"><h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3></div></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
